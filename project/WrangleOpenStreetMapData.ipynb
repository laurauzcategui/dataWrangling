{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle OpenStreetMap Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: [Laura Uzcategui](https://github.com/laurauzcategui/)\n",
    "\n",
    "## Abstract \n",
    "\n",
    "With the amount of increased data and information over Internet and the World, one of the most crucial facts is getting right data processing, meaning cleaning and wrangling that will be most likely used for decision making such as : work, research, life and so on. \n",
    "\n",
    "The content of the following document is based on Exploring, Cleaning and applying Data Wrangling over an area of Dublin picked from OpenStreetMap, which is a project that creates and distributes free geographic data for the world. The most important thing is the data present in this project is open and free to contribute, which makes sometimes harder to obtain an standard as contributors could introduce data in free-format and everything that comes in free format is prone to error or it could be inaccurate.\n",
    "\n",
    "### Scenario & Dataset \n",
    "\n",
    "For this project I have selected to explore the city I live in: Dublin, Ireland.\n",
    "\n",
    "Specifically the area highlighted in the picture below. \n",
    "\n",
    "![Dublin Map](DublinMap.png)\n",
    "\n",
    "### Tools used\n",
    "- [OpenStreetMap](https://www.openstreetmap.org): Selected the area and coordinates of the map\n",
    "- [OverPass API](https://overpass-api.de/): Used for downloading the data is OSM format matching the coordinates\n",
    "- Python: used for Cleaning & DataWrangling, Insert/Delete Operations and query to Sqlite3\n",
    "- Sqlite3: used as Data Storage \n",
    "- Jupyter Notebooks: Used to document the project\n",
    "\n",
    "### Source \n",
    "\n",
    "- [dublin_openstreet.py](./dublin_openstreet.py): python module that was used for cleaning and wrangling of the data. \n",
    "- [dublin_db.py](./dublin_db.py): python module that contains DB class definition to allow the following operation in sqlite3: \n",
    "    - creation of database\n",
    "    - connection to a database\n",
    "    - drop tables \n",
    "    - create tables\n",
    "    - query execution \n",
    "- [queries.py](./queries.py): python module that contains all the queries to be executed \n",
    "- [dublin_queries.py](./dublin_queries.py): Main python module that contains a CLI in order to allow the user to execute all queries or pass a list of queries to execute. \n",
    "\n",
    "### Background Information\n",
    "\n",
    "Before jumping into the analysis of the data, It's important to define the following concepts: \n",
    "- [Node](https://wiki.openstreetmap.org/wiki/Elements#Node): A node represents a specific point on the earth's surface defined by its latitude and longitude. Each node comprises at least an id number and a pair of coordinates.\n",
    "- [Way](https://wiki.openstreetmap.org/wiki/Elements#Way): A way is an ordered list of between 2 and 2,000 nodes that define a polyline. Ways are used to represent linear features such as rivers and roads\n",
    "- [Tag](https://wiki.openstreetmap.org/wiki/Elements#Tag): All types of data element (nodes, ways and relations), as well as changesets, can have tags. Tags describe the meaning of the particular element to which they are attached.\n",
    "    \n",
    "    A tag consists of two free format text fields; a 'key' and a 'value'. Each of these are Unicode strings of up to 255 characters. For example, highway=residential defines the way as a road whose main function is to give access to people's homes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results \n",
    "\n",
    "The following script is the one executed to get the queries executed after working with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import queries\n",
    "import argparse\n",
    "import textwrap\n",
    "import os\n",
    "\n",
    "from prettytable import from_db_cursor\n",
    "from prettytable import PrettyTable\n",
    "from collections import deque\n",
    "\n",
    "from dublin_db import DB, TABLES\n",
    "from dublin_openstreet import NODES_PATH ,NODE_TAGS_PATH, WAYS_PATH, WAY_NODES_PATH, WAY_TAGS_PATH\n",
    "from dublin_openstreet import expected\n",
    "\n",
    "DB_NAME = \"dublin\"\n",
    "QUERIES = queries.queries\n",
    "QUERY_ALL = \"ALL\"\n",
    "SPECIAL_QUERY = [\"rows_per_table\",\"street_types\"]\n",
    "\n",
    "class QUERY:\n",
    "    def __init__(self):\n",
    "        self.DB = DB(DB_NAME)\n",
    "        self.conn = self.DB.connect_to_db()\n",
    "\n",
    "    def print_description(self):\n",
    "        return textwrap.dedent('''\\\n",
    "         |------------------------------------------------------------------\n",
    "         | Execute your queries in the specified DB :) See the options below:\n",
    "         |------------------------------------------------------------------\n",
    "         | - Execute queries defined over queries.py map.\n",
    "         | - Update queries.py with new queries\n",
    "         | - Pass the option --query_name to execute an specific query\n",
    "         | - Execute multiple queries at once by passing --queries_names option\n",
    "         | Future Versions:\n",
    "         | - Execute all queries\n",
    "         |------------------------------------------------------------------\n",
    "         ''')\n",
    "\n",
    "    def main(self):\n",
    "        ''' Cli to be able to execute a list of queries or one query only'''\n",
    "        parser = argparse.ArgumentParser(description=self.print_description(),\n",
    "                                         prog='dublin_queries',\n",
    "                                         formatter_class=argparse.RawDescriptionHelpFormatter)\n",
    "        group = parser.add_mutually_exclusive_group(required=True)\n",
    "        group.add_argument('--queries_names', dest='query_name', nargs='*',\n",
    "                            help='Execute a list of queries separated by an space. i.e --queries_names a b c')\n",
    "        group.add_argument('--query_name', dest='query_name', help='Execute a query defined in queries.py')\n",
    "\n",
    "        args = parser.parse_args()\n",
    "        self.validate_args(args)\n",
    "        return args\n",
    "\n",
    "    def validate_args(self,args):\n",
    "        ''' Validate that the query or queries passed by CLI args are valid'''\n",
    "        if QUERY_ALL in args.query_name:\n",
    "            return\n",
    "        exist = self.query_exist(args.query_name)\n",
    "        if len(exist) > 0:\n",
    "            print \"The following queries are not registered: {}\".format(', '.join(map(str, exist)))\n",
    "            exit(1)\n",
    "\n",
    "    def query_exist(self,queries_to_check):\n",
    "        ''' Will check if the query is defined at queries.py file'''\n",
    "        invalid_queries = []\n",
    "\n",
    "        queries_registered = QUERIES.keys()\n",
    "        for query in queries_to_check:\n",
    "            if query in queries_registered:\n",
    "                continue\n",
    "            else:\n",
    "                invalid_queries.append(query)\n",
    "        return invalid_queries\n",
    "\n",
    "    def retrieve_query(self,query_to_lookup):\n",
    "        ''' Will retrieve the query statement to be executed only if enabled'''\n",
    "        if QUERIES.get(query_to_lookup) and QUERIES[query_to_lookup][1]:\n",
    "            return QUERIES[query_to_lookup][0]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def execute_queries(self,queries):\n",
    "        ''' Will execute each query on the \"queries\" list\n",
    "           if the query is on SPECIAL_QUERY it will call the method defined over the script\n",
    "           else it will execute the regular query'''\n",
    "        if QUERY_ALL in queries:\n",
    "            queries = QUERIES.keys()\n",
    "        for query in queries:\n",
    "            if query in SPECIAL_QUERY:\n",
    "                getattr(self, query)(query)\n",
    "            else:\n",
    "                statement = self.retrieve_query(query)\n",
    "                if statement is not None:\n",
    "                    print \"Executing query_name:{}\\nQuery: {}\".format(query,statement)\n",
    "                    rows, col_names = self.DB.execute_query(statement)\n",
    "                    print format_result(deque(col_names), rows)\n",
    "                else:\n",
    "                    print \"It looks like query: {} does not exist or it's disabled\".format(query)\n",
    "\n",
    "    def rows_per_table(self, query):\n",
    "        ''' Will loop through the TABLES list and execute the same query for each table'''\n",
    "        for table in TABLES:\n",
    "            statement = self.retrieve_query(query)\n",
    "            if statement is not None:\n",
    "                st = statement.format(table)\n",
    "                rows, col_names = self.DB.execute_query(st)\n",
    "                print \"Table: {}\".format(table)\n",
    "                print format_result(deque(col_names), rows)\n",
    "    \n",
    "    def street_types(self, query):\n",
    "        ''' Will loop in street types cursor and find uniqueness'''\n",
    "        st_types = set()\n",
    "        statement = self.retrieve_query(query)\n",
    "        if statement is not None:\n",
    "            rows, col_names = self.DB.execute_query(statement)\n",
    "            for row in rows:\n",
    "                if row[0].split()[-1] in expected:\n",
    "                    st_types.add(row[0].split()[-1])\n",
    "            print \"Streets types\\n\"\n",
    "            print \"\\n\".join(st_types)\n",
    "\n",
    "def format_result(col_names, rows):\n",
    "    ''' It will format the result of the query with a table shape'''\n",
    "    ptt=PrettyTable()\n",
    "    ptt.padding_width = 1\n",
    "    idx = 0\n",
    "    while len(col_names) > 0:\n",
    "        col_name = col_names.popleft()\n",
    "        if len(col_names) == 0:\n",
    "            # format(row[idx], ',d')\n",
    "            ptt.add_column(col_name, [ \"{}\".format(str(row[idx])) for row in rows])\n",
    "            ptt.align[col_name]=\"r\"\n",
    "        else:\n",
    "            ptt.add_column(col_name,[row[idx] for row in rows])\n",
    "            ptt.align[col_name]=\"l\"\n",
    "        idx += 1\n",
    "    return ptt\n",
    "\n",
    "def print_file_size():\n",
    "    ''' It will print the size of each file'''\n",
    "    files = ['dublin.osm', NODES_PATH ,NODE_TAGS_PATH, WAYS_PATH, WAY_NODES_PATH, WAY_TAGS_PATH]\n",
    "    file_sizeMB = []\n",
    "    for file in files:\n",
    "        file_size = os.path.getsize(file)\n",
    "        format_str = \"{} {}MB\\n\".format(file, float(file_size >> 20))\n",
    "        file_sizeMB.append(format_str)\n",
    "    print textwrap.dedent('''\\\n",
    "|--------------------------\n",
    "| Size of Files\n",
    "|--------------------------\n",
    "| {}---------------------------'''.format(\"| \".join(file_sizeMB)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a QUERY object \n",
    "queries = QUERY()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size Of Files Stats\n",
    "\n",
    "The following method call, will display the size of each file. \n",
    "\n",
    "#### Input Files\n",
    "- dublin.osm \n",
    "\n",
    "#### Output Files\n",
    "- nodes.csv\n",
    "- nodes_tags.csv\n",
    "- ways.csv\n",
    "- ways_nodes.csv\n",
    "- ways_tags.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------------------------\n",
      "| Size of Files\n",
      "|--------------------------\n",
      "| dublin.osm 75.0MB\n",
      "| nodes.csv 22.0MB\n",
      "| nodes_tags.csv 2.0MB\n",
      "| ways.csv 3.0MB\n",
      "| ways_nodes.csv 9.0MB\n",
      "| ways_tags.csv 8.0MB\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "# Get size of files\n",
    "print_file_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows_per_table\n",
      "count_unique_user_by_node\n",
      "ways_most_used_keys\n",
      "street_types\n",
      "nodes_most_used_keys\n",
      "ways_vs_nodes\n",
      "nodes_count_of_streets\n"
     ]
    }
   ],
   "source": [
    "# Print all Queries available \n",
    "print \"\\n\".join(QUERIES.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Queries\n",
    "\n",
    "In the following sections you will see the execution of each query and its description and analysis. \n",
    "\n",
    "#### Query 1: Rows per table\n",
    "Description: This query will be perform in batch and it will retrieve the amount of rows for each table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: nodes\n",
      "+-----------+\n",
      "| row_count |\n",
      "+-----------+\n",
      "|    283111 |\n",
      "+-----------+\n",
      "Table: nodes_tags\n",
      "+-----------+\n",
      "| row_count |\n",
      "+-----------+\n",
      "|     74044 |\n",
      "+-----------+\n",
      "Table: ways\n",
      "+-----------+\n",
      "| row_count |\n",
      "+-----------+\n",
      "|     62846 |\n",
      "+-----------+\n",
      "Table: ways_tags\n",
      "+-----------+\n",
      "| row_count |\n",
      "+-----------+\n",
      "|    251886 |\n",
      "+-----------+\n",
      "Table: ways_nodes\n",
      "+-----------+\n",
      "| row_count |\n",
      "+-----------+\n",
      "|    408653 |\n",
      "+-----------+\n"
     ]
    }
   ],
   "source": [
    "# Rows per table\n",
    "queries.execute_queries(['rows_per_table'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 2: Count of the unique users by Node\n",
    "Description: The following query contains the amount of unique users that contributed to nodes table in the selected area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query_name:count_unique_user_by_node\n",
      "Query: select count(distinct(user)) as distinct_users from nodes;\n",
      "+----------------+\n",
      "| distinct_users |\n",
      "+----------------+\n",
      "|            636 |\n",
      "+----------------+\n"
     ]
    }
   ],
   "source": [
    "# Rows per table\n",
    "queries.execute_queries(['count_unique_user_by_node'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis: \n",
    "The amount of unique users is impressive, 636 users are contributing to the Dublin area selected. \n",
    "\n",
    "\n",
    "##### Idea for Improvement: \n",
    "- There is not enough information if this users are residents or not of Dublin. This information will be useful to the contributors and users of openstreetdata because it can increase somehow the level of trust on the data that is being added. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 3: Nodes most used keys\n",
    "\n",
    "Description: The idea behind the execution of this query was to get the top keys and for that I have defined a limit on the count, therefore the query will retrieve all keys where the count was above 1000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query_name:nodes_most_used_keys\n",
      "Query: select a.* from ( select count(key) as count, key from nodes_tags group by key order by count desc ) a where a.count >= 1000;\n",
      "+-------+------------------+\n",
      "| count |              key |\n",
      "+-------+------------------+\n",
      "| 6645  |             name |\n",
      "| 6152  |           street |\n",
      "| 4393  |             city |\n",
      "| 4153  |      housenumber |\n",
      "| 4133  |          amenity |\n",
      "| 3019  |          highway |\n",
      "| 2847  |         operator |\n",
      "| 2547  |          website |\n",
      "| 1849  |          natural |\n",
      "| 1711  |          barrier |\n",
      "| 1696  |             shop |\n",
      "| 1483  |            phone |\n",
      "| 1378  |              ref |\n",
      "| 1345  | public_transport |\n",
      "| 1338  |       wheelchair |\n",
      "| 1322  |          network |\n",
      "| 1233  |              bus |\n",
      "| 1147  |  traffic_calming |\n",
      "| 1117  |  postal_district |\n",
      "| 1075  |          shelter |\n",
      "| 1003  |              lit |\n",
      "+-------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# Rows per table\n",
    "queries.execute_queries(['nodes_most_used_keys'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis: \n",
    "\n",
    "Based on this information, it looks like on of the most contributed nodes was related to: \n",
    "\n",
    "- Street \n",
    "- Amenity \n",
    "- HouseNumber\n",
    "- Highway\n",
    "\n",
    "Therefore the following queries will be based on this information, Specifically queries will be executed against Street, Amenity and HouseNumber.\n",
    "\n",
    "##### Idea for Improvement:\n",
    "\n",
    "* By looking at the tops keys, some of them seems to be related to transportation, therefore a suggestion on tagging will be: \n",
    "\n",
    "    - key: bus\n",
    "    - type: transportation \n",
    "\n",
    "    - key: highway\n",
    "    - type: transportation\n",
    "\n",
    "* Also another idea could be around merging data, for example, bus and public_transport keys could be seen as one by using the idea above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 3: Nodes count of Streets \n",
    "\n",
    "Description: This query will get the count of unique number of streets reported in Nodes table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query_name:nodes_count_of_streets\n",
      "Query: select count(value) as 'Number of Streets' from (select distinct(value) as value from nodes_tags where key='street');\n",
      "+-------------------+\n",
      "| Number of Streets |\n",
      "+-------------------+\n",
      "|               895 |\n",
      "+-------------------+\n"
     ]
    }
   ],
   "source": [
    "# Rows per table\n",
    "queries.execute_queries(['nodes_count_of_streets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis: \n",
    "There is approximately 900 streets accounted in the nodes tables in the selected Dublin area. Nevertheless I consider the tagging could be improved, I could find different types of streets like the followings: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streets types\n",
      "\n",
      "Lane\n",
      "Square\n",
      "Quay\n",
      "Cottages\n",
      "Grove\n",
      "Park\n",
      "Drive\n",
      "Mews\n",
      "Crescent\n",
      "Place\n",
      "Terrace\n",
      "Villas\n",
      "Village\n",
      "Lawn\n",
      "Court\n",
      "View\n",
      "Avenue\n",
      "Gardens\n",
      "Road\n",
      "Hill\n"
     ]
    }
   ],
   "source": [
    "queries.execute_queries(['street_types'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Idea for Improvement:\n",
    "\n",
    "* All the streets types above I consider should be marked as sub type of the tag, this way the tag definition will look like this: \n",
    "\n",
    "    - key: street \n",
    "    - value: Tivoli Avenue\n",
    "    - type: addr\n",
    "    - sub-type: Avenue\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 4: Ways vs Nodes\n",
    "\n",
    "Description: the purpose of the query is to analise if there is consistency between the values field when the key is \"street\" in the nodes_tags and ways_tags table. For achieving the goal a join between 3 tables has to be executed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query_name:ways_vs_nodes\n",
      "Query: \n",
      "select nt.id as node_id, nt.value as node_value, wt.id as way_id, wt.value as way_value\n",
      "  from (\n",
      "    select distinct wn.id as way, wn.node_id as node\n",
      "    from ways_nodes wn, nodes_tags nt, ways_tags wt\n",
      "    where wn.id = wt.id and wn.node_id = nt.id\n",
      "  ) a, nodes_tags nt, ways_tags wt\n",
      "where wt.key='street' and\n",
      "      nt.key = 'street'and\n",
      "      a.way = wt.id and\n",
      "      a.node = nt.id and\n",
      "      wt.value != nt.value;\n",
      "\n",
      "+------------+---------------------+-----------+--------------------------+\n",
      "| node_id    | node_value          | way_id    |                way_value |\n",
      "+------------+---------------------+-----------+--------------------------+\n",
      "| 516031805  | Hanover Quay        | 119453161 |            Forbes Street |\n",
      "| 1443560444 | Templeville Road    | 131118307 |           Wainsfort Road |\n",
      "| 2211597932 | Saint Aidan's Drive | 211151340 |          Hollywood Drive |\n",
      "| 2435404944 | Charlemont Court    | 235543191 |          Charlemont Mall |\n",
      "| 2435404952 | Charlemont Court    | 235543191 |          Charlemont Mall |\n",
      "| 2435830429 | Charlemont Court    | 235543191 |          Charlemont Mall |\n",
      "| 2562653740 | Asgard Road         | 119453174 | Sir John Rogerson's Quay |\n",
      "| 3559946605 | Dublin Castle       | 243022013 |            Castle Street |\n",
      "| 3972487619 | Erne Place Little   | 57364661  |              Harmony Row |\n",
      "+------------+---------------------+-----------+--------------------------+\n"
     ]
    }
   ],
   "source": [
    "queries.execute_queries(['ways_vs_nodes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis: \n",
    "\n",
    "In the result above, you can observe how the nodes and ways presents in the tables nodes_tags and ways_tags are present as a relationship marked in ways_nodes table. \n",
    "\n",
    "**Possible problems and solution**:\n",
    "\n",
    "- Charlemount Court node\n",
    "    - Problem: It's repeated 3 times with different ids and same way id. \n",
    "    - Solution: consolidate the data to be the same node. \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The project has been a really good experience and a way to experiment with a long dataset that from the very beginning requires a lot of work from understanding the purpose of the elements to study, cleaning and wrangling the data until finally getting it shaped, so that it could be analysed and explored easily through SQL. \n",
    "\n",
    "I would say, there is more work to be done on this project in terms of extendig the amount of queries that could help the community to analise the data from openstreetmap and make it richer and cleaner than it is now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'WrangleOpenStreetMapData.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
